{"cells":[{"cell_type":"markdown","metadata":{"id":"r5DYPXQks8W8"},"source":["# __Hands-on with TensorFlow: Part A__\n","\n","Let's see how TensorFlow works and build a deep neural network model using the MNIST dataset."]},{"cell_type":"markdown","source":["## Steps to be followed:\n","1. Import TensorFlow\n","2. Load the MNIST dataset\n","3. Create the model\n","4. Get predictions from the model\n","5. Apply softmax activation to the predictions\n","6. Define the loss function\n","7. Compile the model\n","8. Train the model\n","9. Evaluate the model\n","10. Create a probability model"],"metadata":{"id":"-ECDrQx60xoq"}},{"cell_type":"markdown","metadata":{"id":"FVLJK59QIE4L"},"source":["## Step 1: Import TensorFlow\n","\n","- Import TensorFlow and check its version.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6815,"status":"ok","timestamp":1716012622540,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"u2tOxjHDHMKV","outputId":"1f9cf7f2-8642-4859-e913-f763d9502aa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.15.0\n"]}],"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","import tensorflow as tf\n","print(\"TensorFlow version:\", tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"9Kzn0RkDJISF"},"source":["## Step 2: Load the MNIST dataset\n","\n","- Load the MNIST dataset and normalize the input data by dividing the train and test sets by 255.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1817,"status":"ok","timestamp":1716012624352,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"skfLvH-nHMKX","outputId":"95ca937d-d1ff-4472-f769-eb0dad7640df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}],"source":["mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0"]},{"cell_type":"markdown","metadata":{"id":"65QMopVDbRV_"},"source":["__Observation:__\n","- The dataset has been downloaded."]},{"cell_type":"markdown","metadata":{"id":"jNMOqMYQJLig"},"source":["## Step 3: Create the model\n","\n","- Create a Sequential model with flatten, dense, and dropout layers.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mtWDjnQ-HMKY"},"outputs":[],"source":["model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28)),\n","  tf.keras.layers.Dense(128, activation='relu'),\n","  tf.keras.layers.Dropout(0.2),\n","  tf.keras.layers.Dense(10)\n","])"]},{"cell_type":"markdown","metadata":{"id":"-OeXA6kqJOS9"},"source":["## Step 4: Get predictions from the model\n","\n","- Get the predictions from the model using the train data for one column, as the optimizer is not yet applied.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716012624352,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"EEXrOQBIHMKY","outputId":"e7fc91da-3fb4-4679-b054-7a4ee9fc535f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.0162375 , -0.31711754, -0.69144183,  1.1094426 , -0.15561691,\n","        -0.44989958, -0.0533486 , -0.15329298, -0.3529281 , -0.47759974]],\n","      dtype=float32)"]},"metadata":{},"execution_count":4}],"source":["predictions = model(x_train[:1]).numpy()\n","predictions"]},{"cell_type":"markdown","metadata":{"id":"253Rri_7bYGW"},"source":["__Observation:__\n","- An array of predicted values is displayed."]},{"cell_type":"markdown","metadata":{"id":"CRWveFSDJQ1g"},"source":["## Step 5: Apply softmax activation to the predictions\n","\n","- Apply softmax activation to the predictions and print the output in terms of probabilities.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716012624352,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"wBEJwtZTHMKZ","outputId":"1accdcb5-3efd-4429-ff7a-f2b0f282a92e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.10265802, 0.07355609, 0.05058848, 0.30631328, 0.0864485 ,\n","        0.06440983, 0.09575732, 0.08664963, 0.07096861, 0.06265014]],\n","      dtype=float32)"]},"metadata":{},"execution_count":5}],"source":["tf.nn.softmax(predictions).numpy()"]},{"cell_type":"markdown","metadata":{"id":"FbeDR5bZbk_x"},"source":["__Observation:__\n","- The predicted values in terms of probabilities are displayed as an array."]},{"cell_type":"markdown","metadata":{"id":"PI12JfM-JToW"},"source":["## Step 6: Define the loss function\n","\n","- Create a loss function for the model.\n","- Define the SparseCategoricalCrossentropy loss function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZ6pLV9zHMKZ"},"outputs":[],"source":["loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":647,"status":"ok","timestamp":1716012624996,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"AAnHjWvTHMKZ","outputId":"893ed7ad-de14-48ee-cf91-11cb507e8a75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.742489"]},"metadata":{},"execution_count":7}],"source":["loss_fn(y_train[:1], predictions).numpy()"]},{"cell_type":"markdown","metadata":{"id":"w5HvjqdUH0WN"},"source":["__Observation:__\n","- Here, the value is 2.061."]},{"cell_type":"markdown","metadata":{"id":"XVXzZg9iJZaG"},"source":["## Step 7: Compile the model\n","\n","- Compile the model with the Adam optimizer, the loss function, and the accuracy metric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YKnSLj5vHMKa"},"outputs":[],"source":["model.compile(optimizer='adam',\n","              loss=loss_fn,\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"p_F7rCgcIEMG"},"source":["__Observation:__\n","- Here, we have used an optimizer as Adam, loss as a loss function, and metrics as accuracy."]},{"cell_type":"markdown","metadata":{"id":"-AnMOFCkJcgv"},"source":["## Step 8: Train the model\n","\n","- Fit the model using the training data for 5 epochs.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44605,"status":"ok","timestamp":1716012669599,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"5hjrBy1aHMKa","outputId":"67ffb3d4-1f25-4c22-8cd7-83564ddb8800"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 16s 7ms/step - loss: 0.2974 - accuracy: 0.9144\n","Epoch 2/5\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1434 - accuracy: 0.9577\n","Epoch 3/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.1066 - accuracy: 0.9675\n","Epoch 4/5\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0891 - accuracy: 0.9729\n","Epoch 5/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.0752 - accuracy: 0.9771\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b58fca9ae90>"]},"metadata":{},"execution_count":9}],"source":["model.fit(x_train, y_train, epochs=5)"]},{"cell_type":"markdown","metadata":{"id":"GHvNMdBKbv1X"},"source":["__Observations:__\n","- The model fits the data.\n","- Here, we can see that the accuracy is increased by different epochs."]},{"cell_type":"markdown","metadata":{"id":"m0WyyUkmJfL2"},"source":["## Step 9: Evaluate the model\n","\n","- Evaluate the model using the testing data and print the results.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1053,"status":"ok","timestamp":1716012670644,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"VzaL0IbfHMKa","outputId":"5e3c2268-e7ad-4fd4-d042-70bc0c3f5cfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 - 1s - loss: 0.0705 - accuracy: 0.9791 - 622ms/epoch - 2ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.07045573741197586, 0.9790999889373779]"]},"metadata":{},"execution_count":10}],"source":["model.evaluate(x_test,  y_test, verbose=2)"]},{"cell_type":"markdown","metadata":{"id":"VP4xBW0Bb1Np"},"source":["__Observation:__\n","\n","- The accuracy score is 0.9779, and the loss is 0.071."]},{"cell_type":"markdown","metadata":{"id":"U4u4wC6hJiU-"},"source":["## Step 10: Create a probability model\n","\n","- Create a probability model by adding the softmax layer to the existing model.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYpCfUUhHMKb"},"outputs":[],"source":["probability_model = tf.keras.Sequential([\n","  model,\n","  tf.keras.layers.Softmax()\n","])"]},{"cell_type":"markdown","metadata":{"id":"F3B91f33Aop5"},"source":["- Get the predictions using the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716012670645,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"LsDR4IHiHMKb","outputId":"4ba3a58b-49db-42a7-f6a0-30078a0359bc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 10), dtype=float32, numpy=\n","array([[2.35514889e-07, 2.79866819e-09, 3.38143991e-06, 2.87143248e-05,\n","        9.86441614e-13, 2.89823674e-07, 6.99302378e-13, 9.99965787e-01,\n","        3.53454510e-08, 1.63075674e-06],\n","       [1.58909774e-08, 1.07757633e-05, 9.99984145e-01, 2.48720539e-06,\n","        7.20975607e-14, 2.03693148e-07, 1.06905125e-08, 3.28412617e-13,\n","        2.41978705e-06, 9.13098915e-13],\n","       [1.75531738e-06, 9.98370707e-01, 1.04908802e-04, 1.69048635e-05,\n","        7.21752076e-05, 4.27044397e-05, 4.82732576e-05, 1.27938553e-03,\n","        6.06342146e-05, 2.55016516e-06]], dtype=float32)>"]},"metadata":{},"execution_count":12}],"source":["probability_model(x_test[:3])"]},{"cell_type":"markdown","metadata":{"id":"3nKN25BRb785"},"source":["__Observation:__\n","- Here, we have the probabilities for the first three observations and different classes."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 [3.10]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":0}